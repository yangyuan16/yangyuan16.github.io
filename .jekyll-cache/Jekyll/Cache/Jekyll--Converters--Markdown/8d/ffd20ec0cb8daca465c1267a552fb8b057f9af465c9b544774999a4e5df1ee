I";"<h3 id="abstract">Abstract</h3>
<blockquote>
  <p>Notes for reading paper <a href="https://doi.org/10.1016/j.jfineco.2021.08.017">Machine Learning in Chinese Stock Market</a></p>
</blockquote>

<h3 id="main-results">Main results</h3>
<blockquote>
  <p>(1) Neutral networks robustly outperform other methods in terms of 
out-of-sample R^2</p>

  <p>(2) The out-of-sample R^2 are particularly large for the subsamples 
of <font color="red">small firms</font> and non-state-owned firms. Hence,
predictability is more significant for those subsamples of stocks in which <font color="red">retail traders</font> plays a much bigger role.</p>

  <p>(3) Comparing the out-of-sample R^2 with studies in the U.S. market, 
the Chinese market reveals substantially more predictability.</p>

  <p>(4) out-of-sample predictability.</p>

  <p>(5) unconditional and conditional predictive ability test.</p>

  <p>(6) explores whether predictability translates into portfolio gains.</p>

</blockquote>

<h3 id="other-results">other results</h3>
<blockquote>
  <p>We also find that predictability of SOEs (国有企业) in terms of out-of-sample predictive R^2 
is <font color="red">weaker</font> than for <font color="red">non-SOEs</font> at 
a <font color="red">monthly prediction horizon</font>, which confirms the SOE’s reputation of 
being <font color="red">non-transparent</font> (国企的声誉并不透明).</p>

  <p>Our results indicate that also that a long-only portfolio can provide substantial and, 
even after including transaction costs, economically signicant performance
(我们的结果还表明，一个只做多的投资组合可以提供实质性的、甚至包括交易成本在内的经济显著的业绩 )</p>
</blockquote>

<h3 id="methods-and-data">Methods and Data</h3>
<h4 id="methods">Methods</h4>
<ul>
  <li>
    <p>(1) Apply the empirical design of Gu et al. (2020b) to the Chinese market.</p>
  </li>
  <li>
    <p>(2) linear models:</p>
    <blockquote>
      <p>ordinary least squares regression (OLS)</p>

      <p>partial least squares (PLS)</p>

      <p>least absolute shrinkage and selection operator (LASSO)</p>

      <p>elastic net (Enet)</p>

      <p>gradient boosted regression trees (GBRT)</p>

      <p>random forest (RF)</p>

      <p>variable subsample aggregation (VASA)</p>

      <p>neutral networks with only 5 layers (NN1 - NN5)</p>
    </blockquote>
  </li>
</ul>

<h4 id="data">Data</h4>
<ul>
  <li>
    <p>(1) WIND</p>
  </li>
  <li>
    <p>(2) CSMAR</p>
  </li>
  <li>
    <p>(3) Predictors: <a href="https://doi.org/10.1093/rfs/hhx019">Green et al. 2017</a>.
The characteristic that provide independent information about average US monthly stock return.
A large collection of stock-level predictive characteristic based on the variable definitions in
the original literature listed in <a href="https://doi.org/10.1093/rfs/hhx019">Green et al. 2017</a>, 
and the literature on China-specific factors.</p>
  </li>
</ul>

<h4 id="data-process">Data process</h4>
<ul>
  <li>(1) classify predictors
    <blockquote>
      <p>90 * 1 vector of stock-level characteristics, 11 * 1 vector of macroeconomic predictors,
80 * 1 vector of dummy variables</p>
    </blockquote>
  </li>
  <li>(2) interaction term between two groups of predictors
    <blockquote>
      <p>Using <font color="red">Kronecker product</font> (直乘) to represent the interaction terms 
between stock-level characteristics and the eleven macroeconomic predictors:
<img src="http://yangyuan16.github.io//images/posts/Quantitative_analysis/kron_predictors.jpg" alt="" /></p>
    </blockquote>
  </li>
</ul>

<h3 id="empirical-analysis">Empirical analysis</h3>

<ul>
  <li>
    <p>We start exploring our models’ prediction performance via out-of-sample 
predictive \(R^2\) and discuss predictability across different subsamples of our data.</p>
  </li>
  <li>
    <p>Table1:</p>
    <blockquote>
      <p><img src="http://yangyuan16.github.io//images/posts/Quantitative_analysis/ML_ch_table1.jpg" alt="" /></p>
      <ul>
        <li>将样本进行 SOEs 和 non-SOEs 分类的原因：
 As state-owned enterprises (SOEs) play an prominent in China’s capital markets and are
 often criticized for information transparency, we explore the R^2 for both SOEs and 
 non-SOEs.</li>
        <li>将样本进行 70% - 30% 分割的原因：<a href="https://doi.org/10.1016/j.jfineco.2019.03.008">As Liu et al. (2019)</a> 
 argue, the samllest 30% of firms often serve as potential shells in reverse 
mergers that circumvent tight IPO constraints. (正如Liu等人（2019年）所说，最小的30%的公司通常是潜在
的规避严格IPO约束的反向合并中的空壳 ) At the same time, Chinese retail investors have a
 notorious preference for investing in small stocks, in particular growth and 
 glamour stocks.(与此同时，中国散户投资者对小型股的投资偏好很强，尤其是增长型和魅力型股票 )</li>
        <li>将样本按 market capitalization per shareholder 分割的原因：To shed light on 
the connection between predictability and retail investors, we further conduct
subgroup analysis based on the average market capitalization per shareholder.
At last, we investigate model predictability by looking into the out-of-sample
R^2 for thses two groups.</li>
        <li>OLS model: OLS model achieves a positive R^2 of 0.81%, showing even the simplest model
 still has some predictive power. The R^2 for OLS-3 is slightly lower than that for OLS
 (0.77% v.s. 0.81%), indicating the three covariates alone (size, book-to-market, and
 momentum) are insufficient to account for all predictive power in linear models. <font color="red">It is 
 noteworthy that the OLS model performs much better in China's stock market than 
 in the U.S. stock market </font></li>
        <li>For PLS, LASSO, and Enet, <font color="red"> the improvement of the R^2 directly
 reflect the effectiveness of dimension reduction when we are faced with 
 a large set of covariates </font>. (对于 PLS, LASSO, Enet, R^2 的提升反映了面对大量协变量
 时降维的有效性。)</li>
        <li>因此，R2的这种提升表明，一些股票特征对于预测中国股市的月度回报是多余的，
 这与<a href="https://doi.org/10.1093/rfs/hhaa009">顾等人（2020b）</a> 对美国市场的研究结果很好地吻合.</li>
        <li>树模型、GBRT和RF以及五个神经网络模型都对 R^2 有所改进,
在所有七种型号中甚至进一步达到2%以上。
这种改进证明了机器学习方法在捕捉预测<font color="red">因子之间复杂交互方面的优势</font>，<a href="https://doi.org/10.1093/rfs/hhaa009">Gu等人（2020b）</a> 也强调了这一点。</li>
        <li>The results in Table 1 suggest that all models have a much better predictive performance
for small stocks. The linear models, the linear models, OLS and OLS-3, now
raise their R^2 to above 1%, while the regularized linear model, including PLS, 
LASSO, and Enet, nearly double their performance.</li>
        <li>负的 R^2: Interestingly, OLS, RF, and even GBRT, now have negative R^2, indicating
they are easily dominated by <font color="red">a naive forecast of zero returns</font>
for all stocks in all periods.</li>
      </ul>
    </blockquote>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>Table2:
    <blockquote>
      <p><img src="http://yangyuan16.github.io//images/posts/Quantitative_analysis/ML_ch_table2.jpg" alt="" /></p>
      <ul>
        <li>表明机器学习方法可以在更长的时间内成功地隔离持续风险溢价: We find that the annual
out-of-sample R^2 are higher than their monthly counterparts, indicating machine learning
methods can successfully isolate persistent risk premiums at longer horizons.<br />
*我们将短期可预测性（尤其是小型股）归因于散户投资者在中国股市中的突出作用。
正如我们稍后将看到的，在较短的视野内，神经网络更加重视小盘股的波动性和动量相关变量，
这可能反映了散户投资者的短期投机行为，以及他们的知名度也就是喜欢优先交易小型股</li>
      </ul>
    </blockquote>
  </li>
</ul>

<p><br /></p>
<ul>
  <li>Table4:</li>
</ul>

<blockquote>
  <p>Given the large number of predictors, we next investigate whether certain predictors are more important than others. 
To this end, we differentiate between the macroeconomic variables and the stock characteristics.
(鉴于预测因素数量众多，我们接下来研究某些预测因素是否比其他预测因素更重要。为此，我们区分了宏观经济变量和股票特征。 )
<img src="http://yangyuan16.github.io//images/posts/Quantitative_analysis/ML_ch_table4.jpg" alt="" /></p>
</blockquote>

:ET