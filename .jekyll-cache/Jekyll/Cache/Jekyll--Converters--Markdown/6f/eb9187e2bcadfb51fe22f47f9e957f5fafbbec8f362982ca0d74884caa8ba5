I"?P<h3 id="abstract">Abstract</h3>
<blockquote>
  <p>Notes for reading paper <a href="https://doi.org/10.1016/j.jfineco.2021.08.017">Machine Learning in Chinese Stock Market</a></p>
</blockquote>

<h3 id="main-results">Main results</h3>
<blockquote>
  <p>(1) Neutral networks robustly outperform other methods in terms of 
out-of-sample R^2</p>

  <p>(2) The out-of-sample R^2 are particularly large for the subsamples 
of <font color="red">small firms</font> and non-state-owned firms. Hence,
predictability is more significant for those subsamples of stocks in which <font color="red">retail traders</font> plays a much bigger role.</p>

  <p>(3) Comparing the out-of-sample R^2 with studies in the U.S. market, 
the Chinese market reveals substantially more predictability.</p>

  <p>(4) out-of-sample predictability.</p>

  <p>(5) unconditional and conditional predictive ability test.</p>

  <p>(6) explores whether predictability translates into portfolio gains.</p>

</blockquote>

<h3 id="other-results">other results</h3>
<blockquote>
  <p>We also find that predictability of SOEs (国有企业) in terms of out-of-sample predictive R^2 
is <font color="red">weaker</font> than for <font color="red">non-SOEs</font> at 
a <font color="red">monthly prediction horizon</font>, which confirms the SOE’s reputation of 
being <font color="red">non-transparent</font> (国企的声誉并不透明).</p>

  <p>Our results indicate that also that a long-only portfolio can provide substantial and, 
even after including transaction costs, economically signicant performance
(我们的结果还表明，一个只做多的投资组合可以提供实质性的、甚至包括交易成本在内的经济显著的业绩 )</p>
</blockquote>

<h3 id="methods-and-data">Methods and Data</h3>
<h4 id="methods">Methods</h4>
<ul>
  <li>
    <p>(1) Apply the empirical design of Gu et al. (2020b) to the Chinese market.</p>
  </li>
  <li>
    <p>(2) linear models:</p>
    <blockquote>
      <p>ordinary least squares regression (OLS)</p>

      <p>partial least squares (PLS)</p>

      <p>least absolute shrinkage and selection operator (LASSO)</p>

      <p>elastic net (Enet)</p>

      <p>gradient boosted regression trees (GBRT)</p>

      <p>random forest (RF)</p>

      <p>variable subsample aggregation (VASA)</p>

      <p>neutral networks with only 5 layers (NN1 - NN5)</p>
    </blockquote>
  </li>
</ul>

<h4 id="data">Data</h4>
<ul>
  <li>
    <p>(1) WIND</p>
  </li>
  <li>
    <p>(2) CSMAR</p>
  </li>
  <li>
    <p>(3) Predictors: <a href="https://doi.org/10.1093/rfs/hhx019">Green et al. 2017</a>.
The characteristic that provide independent information about average US monthly stock return.
A large collection of stock-level predictive characteristic based on the variable definitions in
the original literature listed in <a href="https://doi.org/10.1093/rfs/hhx019">Green et al. 2017</a>, 
and the literature on China-specific factors.</p>
  </li>
</ul>

<h4 id="data-process">Data process</h4>
<ul>
  <li>(1) classify predictors
    <blockquote>
      <p>90 * 1 vector of stock-level characteristics, 11 * 1 vector of macroeconomic predictors,
80 * 1 vector of dummy variables</p>
    </blockquote>
  </li>
  <li>(2) interaction term between two groups of predictors
    <blockquote>
      <p>Using <font color="red">Kronecker product</font> (直乘) to represent the interaction terms 
between stock-level characteristics and the eleven macroeconomic predictors:
<img src="http://yangyuan16.github.io//images/posts/Quantitative_analysis/kron_predictors.jpg" alt="" />
We first explore the variable importance of 11 macroeconomic variables and<br />
94 stock characteristics for all prediction models based on the Chinese stock market.
The variable improtance is defined similarly as in <a href="https://doi.org/10.1093/rfs/hhaa009">Gu et al. (2020b)</a>.</p>
    </blockquote>
  </li>
</ul>

<h3 id="empirical-analysis">Empirical analysis</h3>

<ul>
  <li>
    <p>We start exploring our models’ prediction performance via out-of-sample 
predictive \(R^2\) and discuss predictability across different subsamples of our data.</p>
  </li>
  <li>
    <p>Table1:</p>
    <blockquote>
      <p><img src="http://yangyuan16.github.io//images/posts/Quantitative_analysis/ML_ch_table1.jpg" alt="" /></p>
      <ul>
        <li>将样本进行 SOEs 和 non-SOEs 分类的原因：
 As state-owned enterprises (SOEs) play an prominent in China’s capital markets and are
 often criticized for information transparency, we explore the R^2 for both SOEs and 
 non-SOEs.</li>
        <li>将样本进行 70% - 30% 分割的原因：<a href="https://doi.org/10.1016/j.jfineco.2019.03.008">As Liu et al. (2019)</a> 
 argue, the samllest 30% of firms often serve as potential shells in reverse 
mergers that circumvent tight IPO constraints. (正如Liu等人（2019年）所说，最小的30%的公司通常是潜在
的规避严格IPO约束的反向合并中的空壳 ) At the same time, Chinese retail investors have a
 notorious preference for investing in small stocks, in particular growth and 
 glamour stocks.(与此同时，中国散户投资者对小型股的投资偏好很强，尤其是增长型和魅力型股票 )</li>
        <li>将样本按 market capitalization per shareholder 分割的原因：To shed light on 
the connection between predictability and retail investors, we further conduct
subgroup analysis based on the average market capitalization per shareholder.
At last, we investigate model predictability by looking into the out-of-sample
R^2 for thses two groups.</li>
        <li>OLS model: OLS model achieves a positive R^2 of 0.81%, showing even the simplest model
 still has some predictive power. The R^2 for OLS-3 is slightly lower than that for OLS
 (0.77% v.s. 0.81%), indicating the three covariates alone (size, book-to-market, and
 momentum) are insufficient to account for all predictive power in linear models. <font color="red">It is 
 noteworthy that the OLS model performs much better in China's stock market than 
 in the U.S. stock market </font></li>
        <li>For PLS, LASSO, and Enet, <font color="red"> the improvement of the R^2 directly
 reflect the effectiveness of dimension reduction when we are faced with 
 a large set of covariates </font>. (对于 PLS, LASSO, Enet, R^2 的提升反映了面对大量协变量
 时降维的有效性。)</li>
        <li>因此，R2的这种提升表明，一些股票特征对于预测中国股市的月度回报是多余的，
 这与<a href="https://doi.org/10.1093/rfs/hhaa009">顾等人（2020b）</a> 对美国市场的研究结果很好地吻合.</li>
        <li>树模型、GBRT和RF以及五个神经网络模型都对 R^2 有所改进,
在所有七种型号中甚至进一步达到2%以上。
这种改进证明了机器学习方法在捕捉预测<font color="red">因子之间复杂交互方面的优势</font>，<a href="https://doi.org/10.1093/rfs/hhaa009">Gu等人（2020b）</a> 也强调了这一点。</li>
        <li>The results in Table 1 suggest that all models have a much better predictive performance
for small stocks. The linear models, the linear models, OLS and OLS-3, now
raise their R^2 to above 1%, while the regularized linear model, including PLS, 
LASSO, and Enet, nearly double their performance.</li>
        <li>负的 R^2: Interestingly, OLS, RF, and even GBRT, now have negative R^2, indicating
they are easily dominated by <font color="red">a naive forecast of zero returns</font>
for all stocks in all periods.</li>
      </ul>
    </blockquote>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>Table2:
    <blockquote>
      <p><img src="http://yangyuan16.github.io//images/posts/Quantitative_analysis/ML_ch_table2.jpg" alt="" /></p>
      <ul>
        <li>表明机器学习方法可以在更长的时间内成功地隔离持续风险溢价: We find that the annual
out-of-sample R^2 are higher than their monthly counterparts, indicating machine learning
methods can successfully isolate persistent risk premiums at longer horizons.<br />
*我们将短期可预测性（尤其是小型股）归因于散户投资者在中国股市中的突出作用。
正如我们稍后将看到的，在较短的视野内，神经网络更加重视小盘股的波动性和动量相关变量，
这可能反映了散户投资者的短期投机行为，以及他们的知名度也就是喜欢优先交易小型股</li>
      </ul>
    </blockquote>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>Table4:
    <blockquote>
      <p>Given the large number of predictors, we next investigate whether certain predictors are more important than others. 
To this end, we differentiate between the macroeconomic variables and the stock characteristics.
(鉴于预测因素数量众多，我们接下来研究<font color="red">某些预测因素是否比其他预测因素更重要</font>。
为此，我们区分了宏观经济变量和股票特征。)
<img src="http://yangyuan16.github.io//images/posts/Quantitative_analysis/ML_ch_table4.jpg" alt="" /></p>
      <ul>
        <li>Table 4 reports the relative variable importance of our 11 <font color="red"> macroeconomic variables </font></li>
        <li>For PLS, ntis, which measure the level of <font color="red">issuance activity</font>, has the largest 
variable importance. (对于 PLS, ntis 拥有最大的 variable importance)</li>
        <li>China has been adopting an approval-based IPO system ever since its stock market opened, and it is wellknown 
that the China Securities Regulatory Commission often suspends or reduces the volume of  IPOs when the market is 
down, making it reasonable for ntis to play an important role in predicting monthly returns.  (中国自股票市场开放以来一直采用基于批准的IPO制度，
众所周知，<font color="red">中国证监会经常在市场下跌时暂停或减少IPO数量</font>，这使得NTI在预测月度回报方面发挥重要作用是合理的。 )</li>
        <li>值得注意的是 ntis 是 GBRT 最重要的 macroeconomic variable 同时也是 neural networks 第二重要的 variable.</li>
        <li>
          <font> 如何证明树模型能够检验出 predictors 之间复杂的非线性相互作用 </font>
          <p>(The distribution 
of macroeconomic variable importance for tree models GBRT and RF is relatively more 
uniform than other regression-based methods, indicating these two methods can detect 
potentially complicated nonlinear interactions between macroeconomic variables and 
stock characteristics) 与其他基于回归的方法相比，<font color="red">树模型GBRT和RF的宏观经济变量重要性
分布相对更加均匀</font>，表明这两种方法可以检测宏观经济变量和股票特征之间潜在的<font color="red">复杂非线性相互作用</font>.</p>
        </li>
      </ul>
    </blockquote>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>Figure 1:
    <blockquote>
      <p><img src="http://yangyuan16.github.io//images/posts/Quantitative_analysis/ML_ch_figure1.jpg" alt="" /></p>
      <ul>
        <li>图1汇总了每个宏观经济变量的模型变量重要性。总体而言，我们发现<font color="red">infl和NTI是预测中国股市月收益率的两个最常用的宏观经济变量</font>，
尤其是神经网络。另一方面，股息价格比（dp）、市场波动率（svar）、每股总收益（ep）、期限利差（tms）和市场流动性（mtr）不太重要，
因为大多数模型都忽略了它们。</li>
      </ul>
    </blockquote>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>Figure 2:
    <blockquote>
      <p><img src="http://yangyuan16.github.io//images/posts/Quantitative_analysis/ML_ch_figure2.jpg" alt="" /></p>
      <ul>
        <li>关于整体变量重要性的排序，发现，在预测中国股市时，<font color="red">与市场流动性相关的股票特征最为相关</font>，
即流动性波动性（std-dolvol和std-turn）、零交易日（zerotrade）和非流动性测度（ill）是最显著的预测因子。</li>
        <li>第二个有影响力的群体包含<font color="red">基本面信号和估值比率</font>，如行业调整后的资产周转率变化（chaotia）、
行业调整后员工变化（chempia）、总市值（mve）、近期收入增长数、nincr、行业调整后利润率变化（chpmia）
和行业调整后账面市值变化（bm_ia）。</li>
        <li>第三组由<font color="red">风险度量</font>组成，包括特殊回报波动率（INDIVOL）、总回报波动率和市场贝塔（beta）。
我们的研究结果与 <a href="https://doi.org/10.1093/rfs/hhaa009">Gu等人（2020b）</a> 在美国市场的研究结果进行了鲜明的对比和差异。
他们发现，<font color="red">传统的价格趋势指标是最具影响力的预测指标</font>，对中国股市来说，
除了最近的<font color="red">最大回报（maxret）外</font>，其他指标的重要性都较低。</li>
        <li>有趣的是，<font color="red">异常周转率( abnormal turnover ratio)（atr）</font> 也是机器学习模型中的一个影响因素（
在总体变量重要性方面排名第三），这是 <a href="https://doi.org/10.1093/rof/rfv059">Pan等人（2015）</a> 最初引入的一个中国特殊因素，
用于捕捉普遍<font color="red">投机交易</font>的影响。</li>
        <li>第四有影响的 predictors 是 trend factor: atr 和 ex_trend , <a href="https://ssrn.com/abstract=3402038">刘等人（2020年）</a> 引入的趋势因子（er_trend）
解释了<font color="red">中国股市价格和成交量的持续趋势</font>。值得注意的是，作者最初引入了atr和er趋势，
以适应中国股市大量活跃个人投资者对经验资产定价的影响。</li>
        <li>先前的研究，如 <a href="https://doi.org/10.1093/rof/rfv059">Pan等人（2015年）</a> 和 <a href="https://ssrn.com/abstract=3402038">Liu等人（2020年）</a> 
已经证明了在因子模型中包含中国特有因素的重要性，而在这里，我们提供了进一步的证据，
证明这些因素在更复杂的机器学习模型中也具有相当大的解释力。</li>
        <li>从实践和理论的角度来看，我们也对 <font color="red"> time variation of the variable importance</font> 更为关注
值得注意的是，特别是对于<font color="red">LASSO</font>而言，2015年前后的变量重要性似乎存在差距，这表明<font color="red">股市发生了结构性变化</font>。
众所周知，中国股市在2015年经历了戏剧性的繁荣和突然崩盘，这可能解释了这一发现 ( <a href="https://ssrn.com/abstract=3402038">Liu et al. 2016</a> ).</li>
        <li>基于树的模型，包括GBRT和RF，倾向于选择比替代模型更广泛的特征集，
这也在 <a href="https://doi.org/10.1093/rfs/hhaa009">Gu等人（2020b）</a> 中观察到。</li>
        <li>同样，流动性变量和基本面信号是GBRT和RF最重要的两组预测因子，但它们的变量顺序与其他模型略有不同。</li>
        <li>另一方面，<font color="red">树模型的变量重要性的时间变化相对较低</font>。在这里，
我们还观察到<font color="red">2015年前后变量重要性的差距</font>，特别是对于RF，如ill、idiovol和maxret。</li>
        <li>VASA在变量重要性方面的行为与PLS非常相似，因为VASA是用线性子模型构建的，但<font color="red">变量重要性的时间变化水平较高 </font>。</li>
        <li>神经网络模型（NN1-NN5）<font color="red">倾向于支持流动性变量、基本信号、
估值比率和中国特有的因素</font>，包括异常周转率（atr）、趋势因子（er_trend）和前十大股东持股比例（top10holderrate）。</li>
        <li>与其他模型相比，<font color="red">神经网络在变量重要性方面具有更大的时间变化，
这表明它们可以检测并解释不同预测因子预测能力中的结构突变</font>。 
我们将这一发现归因于<font color="red">神经网络模型的可行性和适应性</font>，特别是当它们在大量数据的情况下经过调整和良好训练时。</li>
      </ul>
    </blockquote>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>Table5:
    <blockquote>
      <p><img src="http://yangyuan16.github.io//images/posts/Quantitative_analysis/ML_ch_table5.jpg" alt="" /></p>
      <ul>
        <li>单纯的采用 <font color="red">out-of-sample R^2 </font> 作为 model selection 的基准在一些实际情况中表现的并不好。有一些模型
在 out-of-sample R^2 的结果上非常接近，但是 very different performance in reality.
这里我们可以采用 Conditional Superior Predictive Ability (CSPA) 来作为比较不同机器学习模型表现的指标。
这一方法是 <a href="http://dx.doi.org/10.2139/ssrn.3536461">Li, Liao and Quaedvlieg</a> 发展的。</li>
        <li>The USPA test indicates that the naive OLS model and the modi
ed OLS-3 model perform poorly, having the largest total number of <font color="red">rejections</font> (USPA
测试表明，naive OLS模型和修改后的OLS-3模型表现不佳，<font color="red">rejection 总数最大</font>)</li>
        <li>The GBRT, RF, NN3, NN4, and NN5 have uniformly better unconditional prediction 
performance than their alternatives, but the <font color="red">USPA test fails to differentiate their performance</font>.
(GBRT、RF、NN3、NN4和NN5的无条件预测性能均优于其替代方案，<font color="red">但USPA测试未能区分其performance</font>)。</li>
        <li>观察比对 CSAP 的测试结果，CSPA测试使我们能够更全面地区分VASA、NN2和正则化线性模型的预测性能，提供统计证据表明这些模型不如NN4和NN5。</li>
      </ul>
    </blockquote>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>Figure3
    <blockquote>
      <p>Dissecting the <font color="red">predictability performance</font> of NN4 (剖析<font color="red">NN4</font>的可预测性性能 ).
<img src="http://yangyuan16.github.io//images/posts/Quantitative_analysis/ML_ch_figure3.jpg" alt="" /></p>
      <ul>
        <li>Table1 - Table5 以及 Fig.1 - Fig.2 的结果表明，神经网络的predictability performance似乎优于其他模型
这些算法一个经常提到的缺点就是缺乏可解释性。然而，作为一种理智检查，并提供一些关于哪些变量导致了 
considerable predictability, 对可预测性的驱动因素进行深入的挖掘。
为此，我们关注 NN4 模型 得到的 R^2_oos 值 在 samll stocks 和 large stocks 的 月度和年度的差异。</li>
        <li>Panel A, 纵轴表示： moving from the top 70% to the bottom 30% stocks for the monthly strategy
绿色表示：moving 之后重要性增加，红色表示 moving 之后重要性减弱。</li>
        <li>Panel A, 使用NN4 的到 20 个最重要变量的差异 （使用 NN4 预测每月范围内前70% 和后 30% 的股票）。</li>
        <li>Panel A, 当我们从大型股票转向小型股票时，三个最重要的predictor不会改变其重要性顺序: (1) <em>chempia</em>
(2) <em>std_dolvol</em> (3) <em>atr</em> 。 当进入到 annual horizon, 这三个 predictors 的重要性会下降 （正如 Panel B 所示）。</li>
        <li>Panel A, for small stocks, while fundamental variables like cash, nincr, bm_ia, and orgcap obtain less weight.
(zerotrade和std_turnorver等<font color="red">流动性相关</font>predictor对small stocks 的权重更大，
而cash、nincr、bm_ia和orgcap等<font color="red">基本面相关变量</font>的权重对small stocks 较小)</li>
        <li>Panel A, <em>idiovoal</em> 的结果支持了有限套利理论 (theory of limited arbitrage: anomalies become stronger
for high idiosyncratic risk stocks and hence, leading to increased overall predictability)</li>
        <li>Panel A, <em>maxret</em> 的结果也证实了我们的猜测: influence of retail investors on the price dynamics of 
small stocks must be considerable. 如果投资者对与彩票式的回报有着强烈的偏好则极端正回报在股票的截面定价中
显示出显著的可预测性 (As <a href="https://doi.org/10.1016/j.jfineco.2010.08.014">Bali et al. (2011)</a> show, if there is a strong preference among investors
for assets with lottery-like payoffs, extreme positive returns exhibit significant predictability in
the <font color="red"> cross-sectional pricing of stocks </font> ).</li>
      </ul>
    </blockquote>
  </li>
</ul>

:ET